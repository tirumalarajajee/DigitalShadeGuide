<!DOCTYPE html>


<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Tooth Shade Detection</title>
<link rel="manifest" href="manifest.json" />
  <style>
    body { font-family: sans-serif; text-align: center; background: #f0f0f0; }
    #camera { display: none; } /* hidden video stream */
    #snapshot { border: 1px solid #000; display: block; margin: 10px auto; }
    #confidenceFill {
      height: 20px;
      background: gray;
      width: 100px;
      margin: auto;
      color: white;
      line-height: 20px;
    }
  </style>
</head>
<body>
  <h2>ðŸ¦· Detection Mode</h2>
  <video id="camera" autoplay playsinline width="640" height="480"></video>
  <canvas id="snapshot" width="640" height="480"></canvas>
<!-- Add this input for dynamic patient naming -->
<input type="text" id="patientNameInput" placeholder="Enter patient name" />

  <br />
  <label for="modeSelector">Detection Mode:</label>
  <select id="modeSelector">
    <option value="single">Single</option>
    <option value="region">Region</option>
    <option value="merge">Merged</option>
  </select>

  <p id="liveShade">Shade: ---</p>
  <div id="confidenceFill">Î”E00: ---</div>



  <br />
  <button id="saveSingle">Save Single</button>
  <button id="saveRegion">Save Region</button>
  <button id="saveMerge">Save Merged</button>
<button id="shareBtn">Share via WhatsApp</button>

<select id="sourceSelector">
  <option value="desktop">Desktop Camera</option>
  <option value="android">Android Stream</option>
</select>

 <body>
  <h3>Tooth Shade Detection</h3>
  <label for="sourceSelector">Source:</label>
  <select id="sourceSelector">
    <option value="desktop">Desktop Camera</option>
    <option value="android">Android Feed</option>
  </select> <!-- ðŸ”¹ Added selector -->

  <input type="text" id="patientNameInput" placeholder="Enter patient name">
  <video id="camera" autoplay playsinline></video>
  <canvas id="snapshot" width="640" height="480"></canvas>
  <div id="liveShade"></div>
  <div id="confidenceFill"></div>
  <button id="saveSingle">Save Single ROI</button>
  <button id="saveRegion">Save Regions</button>
  <button id="saveMerge">Save Merge</button>
  <button id="shareBtn">Share Report</button>

<script>
/* -------- Existing Code -------- */
// (keep all your service worker, webShades, getAverageRGB, rgbToLab, 
//  findClosestShade, captureShade, saveJSONFile, shareBtn logic as is)

/* -------- Added Code for Android feed -------- */
window.receiveFrame = function(base64Url) { // ðŸ”¹ Android will call this
  const img = new Image();
  img.onload = () => {
    const canvas = document.getElementById("snapshot");
    const ctx = canvas.getContext("2d");
    ctx.drawImage(img, 0, 0, canvas.width, canvas.height);

    // Run shade detection after drawing Android frame ðŸ”¹
    const r = 80;
    const roiX = canvas.width / 2;
    const roiY = canvas.height / 2;
    const data = ctx.getImageData(roiX - r, roiY - r, r * 2, r * 2).data;
    const avg = getAverageRGB(data);
    const [shade, delta] = findClosestShade(avg);

    shadeLive.textContent = `Detected Shade: ${shade}`;
    confidenceFill.textContent = `Î”E00: ${delta.toFixed(2)}`;
    confidenceFill.style.backgroundColor = delta < 3 ? "green" : delta < 6 ? "orange" : "red";
  };
  img.src = base64Url;
};

/* -------- Source switch -------- */
const video = document.getElementById("camera");
const sourceSelector = document.getElementById("sourceSelector");

sourceSelector.onchange = () => {
  const source = sourceSelector.value;
  if (source === "android") {
    // ðŸ”¹ Do nothing â€” wait for Android to call receiveFrame()
    video.srcObject = null; // stop desktop stream if active
  } else if (source === "desktop") {
    // ðŸ”¹ Start local camera
    navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } })
      .then(stream => {
        video.srcObject = stream;
        video.addEventListener("loadeddata", () => {
          function drawLoop() {
            const canvas = document.getElementById("snapshot");
            const ctx = canvas.getContext("2d");
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            const r = 80;
            const roiX = canvas.width / 2;
            const roiY = canvas.height / 2;
            const data = ctx.getImageData(roiX - r, roiY - r, r * 2, r * 2).data;
            const avg = getAverageRGB(data);
            const [shade, delta] = findClosestShade(avg);

            shadeLive.textContent = `Detected Shade: ${shade}`;
            confidenceFill.textContent = `Î”E00: ${delta.toFixed(2)}`;
            confidenceFill.style.backgroundColor = delta < 3 ? "green" : delta < 6 ? "orange" : "red";
            confidenceFill.style.width = Math.min(100, 100 - delta * 5) + "%";

            requestAnimationFrame(drawLoop);
          }
          drawLoop();
        });
      });
  }
};

// ðŸ”¹ Start with desktop mode by default
sourceSelector.value = "desktop";
sourceSelector.onchange();

</script>
</body>
</html>
